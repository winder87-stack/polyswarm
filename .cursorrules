# Polymarket AI Trading Bot - Cursor Rules

## Project Overview
Automated prediction market trading bot using a 5-model AI swarm (Claude, Gemini, GPT, DeepSeek V3.2, Perplexity) with advanced features: real-time news monitoring, historical pattern analysis, multi-source odds aggregation, smart entry timing, category specialization, position management, contrarian detection, and comprehensive risk management.

## Tech Stack
- Python 3.11+
- AI Models: Claude 3.5, Gemini Pro, GPT-3.5/4, DeepSeek V3.2 (OpenRouter), Perplexity Sonar Pro
- Blockchain: Polygon (MATIC), py-clob-client, web3.py, eth-account
- Data: SQLite, pandas, numpy, scikit-learn
- Async: asyncio, aiohttp, concurrent.futures
- News: feedparser (RSS feeds), aiohttp
- CLI: argparse, termcolor, loguru, matplotlib
- Scheduling: APScheduler

## Directory Structure
polymarket-trader/
â”œâ”€â”€ main.py                          # CLI entry point
â”œâ”€â”€ config/
â”‚   â””â”€â”€ categories.yaml              # Category-specific settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ swarm_agent.py           # 5-model AI swarm
â”‚   â”‚   â””â”€â”€ trading_swarm.py         # Trading signals + execution
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model_factory.py         # AI provider classes
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â””â”€â”€ polymarket_client.py     # Polymarket API
â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”œâ”€â”€ risk_manager.py          # Advanced risk limits + Kelly sizing
â”‚   â”‚   â”œâ”€â”€ entry_timing.py          # Entry optimization (TODO)
â”‚   â”‚   â”œâ”€â”€ position_manager.py      # Position lifecycle (TODO)
â”‚   â”‚   â”œâ”€â”€ category_specialist.py   # Category strategies (TODO)
â”‚   â”‚   â””â”€â”€ contrarian_detector.py   # Contrarian signals (TODO)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ news_monitor.py          # Real-time news monitoring
â”‚   â”‚   â””â”€â”€ external_odds.py         # Multi-source odds (TODO)
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ historical_collector.py  # Historical data collection
â”‚   â”‚   â”œâ”€â”€ pattern_analyzer.py      # Pattern recognition
â”‚   â”‚   â”œâ”€â”€ ai_accuracy_tracker.py   # Prediction tracking
â”‚   â”‚   â””â”€â”€ model_calibration.py     # Calibration (TODO)
â”‚   â””â”€â”€ data/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ paper_trading_24h.py         # 24h paper test with risk management
â”‚   â”œâ”€â”€ test_swarm.py                # Test AI models
â”‚   â”œâ”€â”€ test_markets.py              # Test Polymarket connection
â”‚   â”œâ”€â”€ generate_api_keys.py         # Generate Polymarket API keys
â”‚   â”œâ”€â”€ generate_wallet.py           # Generate Polygon wallet
â”‚   â”œâ”€â”€ monitor_paper_trading.py     # Monitor running paper trading
â”‚   â””â”€â”€ test_all_models.py           # Test all 5 AI models
â”œâ”€â”€ data/                            # SQLite databases (ai_predictions.db, historical.db)
â”œâ”€â”€ logs/                            # Trading logs with timestamps
â”œâ”€â”€ reports/                         # Generated analysis reports
â””â”€â”€ requirements.txt                 # All Python dependencies

## AI Swarm Configuration
```python
SWARM_MODELS = {
    "claude": (True, "claude", "claude-3-5-haiku-20241022"),
    "gemini": (True, "google", "gemini-pro"),
    "gpt": (True, "openai", "gpt-3.5-turbo"),
    "deepseek": (True, "openrouter", "deepseek/deepseek-v3.2"),
    "perplexity": (True, "perplexity", "sonar-pro"),
}

# Provider key (2nd tuple element) must match MODEL_CLASSES keys
MODEL_CLASSES = {
    "claude": ClaudeModel,
    "google": GoogleModel,
    "openai": OpenAIModel,
    "openrouter": OpenRouterModel,
    "perplexity": PerplexityModel,
}

MODEL_WEIGHTS = {
    "claude": 1.3,      # Best reasoning
    "gemini": 1.3,      # Strong reasoning
    "gpt": 1.2,         # GPT-3.5/4 capability
    "perplexity": 1.2,  # Has real-time web search!
    "deepseek": 1.0,    # Good baseline, very fast
}
```

## Code Patterns

### Standard Imports
```python
import os
import sys
import asyncio
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime

from loguru import logger
from termcolor import cprint
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent.parent))
load_dotenv()
```

### Async Operations
```python
async def process_markets(markets: List[Market]) -> List[TradingSignal]:
    tasks = [analyze_market(m) for m in markets]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return [r for r in results if not isinstance(r, Exception)]
```

### Error Handling
```python
try:
    result = await operation()
except APIError as e:
    logger.error(f"API error: {e}")
    return None
except Exception as e:
    logger.exception(f"Unexpected: {e}")
    raise
```

### Logging
```python
logger.info(f"ðŸ“Š Analyzing: {market.question[:50]}")
logger.success(f"âœ… Trade: {direction} ${size:.2f}")
logger.warning(f"âš ï¸ Risk: {reason}")
logger.error(f"âŒ Failed: {error}")
```

### Dataclasses for Data Structures
```python
@dataclass
class TradingSignal:
    market: Market
    direction: str  # "YES" or "NO"
    confidence: float  # 0-1
    probability: float
    market_probability: float
    edge: float
    expected_value: float
    reasoning: str
    model_votes: Dict[str, float]
    model_weights: Dict[str, float]
    consensus_summary: str
    news_context: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
```

## Key Rules
1. ALWAYS use dataclasses for data structures
2. ALWAYS add type hints to functions
3. ALWAYS use loguru for logging (not print)
4. ALWAYS check risk limits before trading
5. ALWAYS use async for I/O operations
6. NEVER trade without minimum edge (8%)
7. NEVER commit .env or API keys
8. NEVER use full Kelly - use fractional (0.25x)
9. ALWAYS record predictions for accuracy tracking
10. ALWAYS update portfolio value for drawdown protection
11. ALWAYS enforce volume/liquidity minimums to prevent slippage
12. ALWAYS filter markets BEFORE AI analysis to save API costs

## Environment Variables
```bash
# AI APIs (all 5 recommended for best performance)
ANTHROPIC_API_KEY=           # Claude 3.5 Haiku (best reasoning)
GOOGLE_API_KEY=              # Gemini Pro
OPENAI_API_KEY=              # GPT-3.5/4
OPENROUTER_API_KEY=          # DeepSeek V3.2
PERPLEXITY_API_KEY=          # Perplexity Sonar Pro (web search)

# Polymarket Credentials
POLYGON_WALLET_PRIVATE_KEY=  # Your Polygon wallet private key
POLYGON_WALLET_ADDRESS=      # Your Polygon wallet address
POLYGON_SIGNATURE_TYPE=0     # 0 for direct EOA wallet
POLYMART_API_KEY=           # Polymarket API key
POLYMART_API_SECRET=        # Polymarket API secret
POLYMART_API_PASSPHRASE=    # Polymarket API passphrase

# Trading Configuration
PAPER_TRADING=true           # Set to false for live trading
BANKROLL=1000               # Starting bankroll in USD
MAX_POSITION_SIZE=100       # Max position size in USD
KELLY_FRACTION=0.25         # Conservative Kelly fraction
```

## Free External Data Sources (No API Keys)

- **Google News**: RSS feeds, no auth needed
- **PredictIt**: Public API, no auth needed
- **Metaculus**: Public API, no auth needed
- **RSS Feeds**: NPR, NYT, ESPN, Bloomberg, CoinTelegraph, etc.

## Feature Modules

### News Monitoring (src/services/news_monitor.py)
- NewsSource base class with fetch_latest()
- GoogleNewsSource (FREE RSS feeds), RSSFeedSource (FREE RSS feeds)
- NewsAggregator for deduplication and ranking
- match_news_to_markets() for relevance scoring
- All sources FREE - no API keys required

### External Odds (src/services/external_odds.py)
- PredictItFetcher (free public API, no auth)
- MetaculusFetcher (free public API, no auth)
- ConsensusDetector with SOURCE_WEIGHTS
- All sources are FREE - no API keys required

### Historical Analysis (src/analysis/)
- **historical_collector.py**: SQLite storage, backfill, resolved markets
- **pattern_analyzer.py**: calibration curves, profitable patterns, category analysis
- **ai_accuracy_tracker.py**: track predictions vs outcomes, Brier scores, model ranking
- **model_calibration.py**: isotonic regression calibration (TODO)

### Risk Management (src/strategies/risk_manager.py)
- **Kelly with uncertainty**: Accounts for confidence levels
- **Correlation-adjusted sizing**: Reduces size for related positions
- **DrawdownProtector**: Progressive size reduction and trading pauses
- **PerformanceTracker**: Sharpe/Sortino ratios, max drawdown
- **BankrollManager**: Dynamic risk limits based on drawdown

### AI Accuracy Tracking (src/analysis/ai_accuracy_tracker.py)
- AIPrediction dataclass for storing predictions
- Resolution updates when markets resolve
- Model accuracy ranking with Brier scores
- Calibration adjustments per model
- Ensemble vs individual performance comparison

### Pattern Analysis (src/analysis/pattern_analyzer.py)
- Category accuracy analysis
- Price pattern recognition (flips, final-day movements)
- Volume signal analysis
- Calibration curve generation
- Profitable pattern discovery

### Trading Swarm (src/agents/trading_swarm.py)
- News-aware analysis prompts
- Breaking news fast-path (2-model analysis)
- AI accuracy tracking integration
- Advanced position sizing with risk management
- Perplexity priority for news-related queries

### Planned Features (TODO)
- **External Odds** (src/services/external_odds.py): PredictIt, Metaculus aggregation (FREE only)
- **Entry Timing** (src/strategies/entry_timing.py): Spread, momentum, time-of-day optimization
- **Position Management** (src/strategies/position_manager.py): Scale-in/out, reanalysis
- **Category Specialist** (src/strategies/category_specialist.py): Category-specific strategies
- **Contrarian Detection** (src/strategies/contrarian_detector.py): Sentiment divergence

## Polymarket Specifics

### Chain Configuration
- Network: Polygon Mainnet (Chain ID: 137)
- RPC: https://polygon-rpc.com
- CLOB API: https://clob.polymarket.com
- Gamma API: https://gamma-api.polymarket.com

### Contract Addresses (Polygon)
- USDC: 0x2791Bca1f2de4661ED88A30C99A7a9449Aa84174
- CTF: 0x4D97DCd97eC945f40cF65F87097ACe5EA0476045
- Exchange: 0x4bFb41d5B3570DeFd03C39a9A4D8dE6Bd8B8982E
- Neg Risk Exchange: 0xC5d563A36AE78145C45a50134d48A1215220f80a

### Trading Rules
- Prices: 0.01 to 0.99 (representing probability)
- Size: Number of shares
- Cost: price Ã— shares
- Minimum edge: 8% before fees
- Always check liquidity before trading
- Use paper trading for testing

## AI Swarm Specifics

### Model Priority & Roles
1. **Claude 3.5**: Best reasoning, highest weight (1.3)
2. **Gemini Pro**: Strong reasoning, high weight (1.3)
3. **Perplexity**: Real-time web search for news, high weight (1.2)
4. **GPT-3.5/4**: General intelligence, medium weight (1.2)
5. **DeepSeek V3.2**: Fast baseline, standard weight (1.0)

### Probability Extraction
Look for patterns like:
- "My probability estimate: XX%"
- "XX% chance/probability/likelihood"
- "YES outcome: XX%"
- Extract numbers between 0-100

### Consensus Logic
- Weighted average of model probabilities
- Confidence based on model agreement (low std dev = high confidence)
- Edge = AI probability - market probability
- Minimum confidence: 60% for trading
- Minimum edge: 8% for execution

### Breaking News Mode
- Triggered by news relevance > 0.8
- Uses only 2 fastest models (DeepSeek + Perplexity)
- 30-second timeout, lower confidence threshold
- Fast trade execution with latency tracking

## Risk Management Rules

### Volume & Slippage Protection
ALWAYS enforce these minimums:

Min 24h Volume: $50,000
Min Liquidity: $25,000
Max Order Size: 2% of liquidity
Max Slippage: 2%

Filter markets BEFORE AI analysis to save API costs.
Sort opportunities by volume (highest first).
Log volume/liquidity for every trade decision.

### Multi-Layer Protection
1. **Kelly Criterion**: Uncertainty-adjusted position sizing
2. **Correlation Control**: Reduce size for related positions (up to 50%)
3. **Drawdown Protection**: Progressive size reduction, 25% pause threshold
4. **Bankroll Limits**: Dynamic risk per trade based on drawdown
5. **Weekend Reduction**: 50% smaller positions on weekends

### Advanced Metrics
- **Sharpe Ratio**: Risk-adjusted returns (target >1.5)
- **Sortino Ratio**: Downside-focused Sharpe (>2.0 preferred)
- **Max Drawdown**: Never exceed 25% portfolio loss
- **Win Rate**: Track individual trade success
- **Profit Factor**: Gross profit / gross loss (>1.5 target)

### Bankroll Management
- **Risk per Trade**: 5% normal, 2% in drawdown, 1% severe drawdown
- **Total Exposure**: Never risk >30% of bankroll
- **Growth Scaling**: Risk limits scale with bankroll growth
- **Emergency Stops**: Automatic pause at 25% drawdown

## Testing & Validation

### Testing Commands
```bash
# Test AI models individually
python scripts/test_all_models.py

# Test AI swarm functionality
python scripts/test_swarm.py

# Test Polymarket connection
python scripts/test_markets.py

# Run 24h paper trading test
python scripts/paper_trading_24h.py --hours 24 --interval 60

# Monitor running paper trading
python scripts/monitor_paper_trading.py

# Analyze historical patterns
python main.py analyze-history

# Track AI accuracy
python main.py ai-accuracy --update-resolutions --suggest-weights

# Collect historical data
python main.py collect-history --days 365
```

### Validation Steps
1. **API Keys**: Verify all 5 AI APIs are configured
2. **Wallet**: Ensure Polygon wallet is funded with MATIC
3. **Paper Trading**: Always test in paper mode first
4. **Risk Limits**: Verify position sizes are reasonable
5. **News Integration**: Test news fetching works
6. **Accuracy Tracking**: Monitor prediction vs outcome accuracy

## Common Tasks

### Adding a New AI Model
1. Add class in src/models/model_factory.py
2. Add to SWARM_MODELS in src/agents/swarm_agent.py
3. Add to MODEL_WEIGHTS with appropriate weight
4. Add API key to .env
5. Update test_all_models.py

### Adding a New Trading Strategy
1. Create file in src/strategies/
2. Implement analyze() method returning TradingSignal
3. Add risk management integration
4. Update TradingSwarm to use new strategy
5. Add CLI command in main.py

### Debugging Issues
1. **API Errors**: Check API keys in .env
2. **Network Issues**: Verify internet and API endpoints
3. **Rate Limits**: Add delays between requests
4. **Risk Violations**: Check position sizes and limits
5. **News Failures**: Verify news source APIs

### Performance Optimization
1. **Model Selection**: Use faster models for breaking news
2. **Caching**: Cache market analysis for repeated queries
3. **Async**: Use async for all I/O operations
4. **Batch Processing**: Process markets in batches
5. **Database Indexing**: Optimize SQLite queries

## Response Format
When generating code:
1. Include all necessary imports at the top
2. Add comprehensive docstrings to classes and methods
3. Include full type hints for all parameters and returns
4. Add proper error handling with specific exceptions
5. Use loguru for all logging (no print statements)
6. Follow established patterns from existing code
7. Add unit tests for critical functions
8. Update documentation and comments

When explaining code:
1. Be concise but thorough
2. Reference relevant files and functions
3. Mention potential issues or edge cases
4. Provide working code examples
5. Explain the reasoning behind design decisions

When explaining:
1. Be concise and practical
2. Provide working code examples
3. Mention potential issues or edge cases
4. Reference relevant files in the project
